---
title: "customer segmentation for an airline carrier"
author: "Yurong Fan"
date: "2016-10-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(magrittr)
library(dplyr) #Attaching dplyr library
library(tidyr) #Attaching tidyr library
#install.packages("lubridate")
library(lubridate) #R library to work with date times.
#install.packages("fastcluster")
library(fastcluster)
```

## Introduction

XX airlines, a unique player in the airline carrier industry has endured the threats of intense
competition from large national brands. Started in 18983 as a charter carrier, it has expanded its business
to offer scheduled flight services to various destinations. By 2014, XX airline had survived
bankruptcies, multiple economic recessions, threats of mergers and was now stable and profitable.


## Understanding the data
The original Sun Country data is in .csv file format. We will use R to preprocess the data and
analyze it, but first, find below find a data dictionary.

| Field | Description |
|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| PNRLocatorID | PNR #. This could,be treated as a confirmation number. Multiple flights and segments all roll,up to one PNR #. |
| TicketNum | Ticket Number - An itinerary may have multiple ticket numbers. |
| CouponSeqNbr | Sabre assigned,sequence number of the ticket coupon. Values are 1-16; values 5 and greater,are a result of a conjunctive ticket. |
| ServiceStartCity | Airport code for,the city the flight is leaving from. |
| ServiceEndCity | Airport code for,the city the flight is landing at. |
| PNRCreateDate | Date the ticket was,booked |
| ServiceStartDate | When the flight,takes off |
| PaxName | First 4 digits of,the passenger last name and the first 2 digits of the passenger 1st name |
| EncryptedName | Passenger name in,encrypted format. |
| GenderCode | M for Male and F,for Female |
| Birthdateid | A unique identifier,that allows you to match birthdates across records without actually providing,the birth date. |
| Age | Age of the,passenger at the time of the flight. |
| PostalCode | Postal code of the,location from where the booking was made. |
| BkdClassOfService | What class of,service (e.g. coach, first class, etc.) the passenger booked |
| TrvldClassOfService | What class of,service (e.g. coach, first class, etc.) the passenger travelled. This could,be upgraded later in the flight. |
| BookingChannel | How the passenger,booked the flight. If this is showing a 3 letter code, it's most likely booked, at that airport. UFO is booked in Cancun. |
| BaseFareAmt | Amount of the base,fare (without taxes) of all segments on the ticket. Under certain,circumstances such as bulk, net, award tickets, this value will be blank. |
| TotalDocAmt | Total price of this,ticket document including base fare, taxes and fees stated in the,EquivBaseFareCurrCode. In the case of exchanges this amount may be zero or,may only represent the difference in price from the previous ticket amount |
| UflyRewardsNumber | The rewards number,that was provided when booked. |
| UflyMemberStatus | The Ufly member,status. It will be either Standard or Elite. |
| CardHolder | True or False value,if the member is also a credit card holder. |
| BookedProduct | Free form text,field that is used to put discount codes in |
| EnrollDate | When the member,enrolled in Ufly rewards |
| MarketingFlightNbr | Flight Number |
| MarketingAirlineCode | The Airlines with,which booking was made. We are only interested in ‚ "SY" which is,the code for the airline |
| StopoverCode | O' for Layovers ie,halt in a city for less than 24 hours.'X' for Stopovers that is halt in a,city for more than 24 hours. |

Open the `.csv` data R
```{r}
data<-read.csv("data_small.csv") #Data is stored in the dataframe called “data”
```

Now look at the structure of the data
```{r}
str(data)
```

and summarize it
```{r}
summary(data)
```

## Data Preperation

### Data Cleaning

The following are the attributes that need treatment.

| GenderCode and Birthdateid | Remove rows with faulty Gendercode and BirthdateID |
|----------------------------|----------------------------------------------------|
| Age                        | Replace faulty values with median value            |
| UflyRewardsNumber          | Replace NAs with 0                                 |
| UflyMemberStatus           | Replace Missing values with "non-member"           |
| Duplicate PNRs             | Remove rows with duplicate PNRs                    |
| BookingChannel             | Remove rows with city codes as BookingChannel      |
| Marketing Airline Code     | Remove rows with airline code other than "SY"      |
| Error PNRs                 | Remove error PNRs                                  |

We need to remove rows with faulty Gendercode and BirthdateID
```{r}
#Filtering out records which have NA for BirthdateID
#same as data <- data %>%filter(!is.na(birthdateid)) 
data%<>%filter(!is.na(birthdateid)) 

data$GenderCode<-as.character(data$GenderCode)
data%<>%filter(GenderCode!="")

#Filtering out records which have “” for GenderCode
data$GenderCode<-as.factor(data$GenderCode)
```

Replace faulty values in Age with median value
```{r}
#Replacing negative ages with median value
data$Age[data$Age < 0] <- median(data$Age)

#Replacing age values greater than 120 with median value
data$Age[data$Age > 120] <- median(data$Age)
```

Replace NAs in UflyRewardsNumber with 0
```{r}
#Replace NAs with 0
data$UFlyRewardsNumber[is.na(data$UFlyRewardsNumber)] <- 0
```

Replace Missing values in UflyMemberStatus with “non-member”
```{r}
#Convert factor level data to string
data$UflyMemberStatus<-as.character(data$UflyMemberStatus)

#Replace missing values with “non-ufly” 
data$UflyMemberStatus[data$UflyMemberStatus==''] <-"non-ufly"
```

Retaining only those rows which have single occurrence of PNRLocatorID, CouponSeqNbr, PaxName, ServiceStartCity, ServiceEndCity, ServiceStartDate combination.
```{r}
data%<>%
  group_by(PNRLocatorID,CouponSeqNbr,PaxName,ServiceStartCity,ServiceEndCity,ServiceStartDate)%>%
  filter(n()==1)
```

Remove rows with faulty city codes as BookingChannel. Some rows have city names for Booking Channel.
Replacing faulty data with “Other”
```{r}
data$BookingChannel<-as.character(data$BookingChannel)
data$BookingChannel[data$BookingChannel!="Outside Booking" & 
                      data$BookingChannel!="SCA Website Booking" & 
                      data$BookingChannel!="Tour Operator Portal" & 
                      data$BookingChannel!="Reservations Booking" & 
                      data$BookingChannel!="SY Vacation"] <- "Other"
data$BookingChannel<-as.factor(data$BookingChannel)
```

Remove rows with MarketingAirlineCode code other than “SY”, the airline code for Sun Country.
```{r}
data$MarketingAirlineCode<-as.character(data$MarketingAirlineCode)
data%<>%filter(MarketingAirlineCode=="SY")
data$MarketingAirlineCode<-as.factor(data$MarketingAirlineCode)
```

Creating a new column called error which contains 1 if the PNR is errored or 0 otehrwise.
Error PNR refers to those which do not start with coupon sequence number 1.
```{r}
data%<>%group_by(PNRLocatorID)%>%
  mutate(error= ifelse(min(CouponSeqNbr)!=1,1,0))
```

Retaining only the non errored rows and check how many rows are remaining.
```{r}
data%<>%filter(error==0)
nrow(data)
```

### Data Sampling
Since the data, after transformation, has 3.2 million rows, we take a sample of the data to perform further analysis to facilitate R to handle the data with ease. Since the data is at the level of one row per flight, just taking a random sample of the rows will distort the trip details. So, we take a sample of the PNRLocatorIDs and retain all the records belonging to the sampled PNRs.
```{r}
#Obtain Unique PNRs
uniquePNRs<-unique(data$PNRLocatorID) 

#To produce the same samples every time the code is run
set.seed(1234567)


sample_PNRs<-sample(uniquePNRs,10000)

#Obtaining data related to the sampled 10,000 PNRs
sample_data<-data%>%filter(PNRLocatorID %in% sample_PNRs)
```


### Data Transformation
For the purpose of analysis, attributes are created as a combination of other attributes.

| 1 | UID | Unique ID for every customer |
|----|------------------------|----------------------------------------------------------------------------------------------------------------------------------------|
| 2 | Age Bucket | Bin customer age into 5 age buckets |
| 3 | True Origin | The starting city of every trip |
| 4 | Final destination | The ending city of the trip |
| 5 | True Destination | The actual destination of the trip (City of longest stay) |
| 6 | Oneway-RoundTrip | 1 if the trip was a round trip and 0 if one way |
| 7 | Group Size | Size of the group if the trip constituted of more than one passengers. |
| 8 | Group-Single | 1 if the trip was flown by more than 1 customers and 0 if the trip was flown by a single customer. |
| 9 | Seasonality | Q1 if travel was made in Jan-Mar Q2 if travel was made in Apr-June Q2 if travel was made in July-Sept Q2 if travel was made in Oct-Dec |
| 10 | Days Booked in Advance | Number of days between booking and travel |

First, create a Unique ID for each customer by concatenating Encrypted name, GenderCode and birthdateid.
```{r}

sample_data<-sample_data%>% mutate(uid=paste(EncryptedName,GenderCode,birthdateid,sep=""))
```

Next, we bin the customers' age into 1 of 5 age buckets
```{r}
sample_data%<>%mutate(age_group = 
                        ifelse(Age>=0 & Age<18,"0-17",
                               ifelse(Age>=18 & Age < 25,"18-24",
                                      ifelse(Age>=25&Age<35,"25-34",
                                             ifelse(Age>=35 & Age<55,"35-54",
                                                    ifelse(Age>=55,"55+",0)
                                                    )
                                             )
                                      )
                               )
                    )
```

Next, we determining the true Service Start City for each row in the data. It will be the First city from which the trip started 
```{r}
true_origins<-sample_data%>%
  arrange(PNRLocatorID,CouponSeqNbr)%>%
  group_by(PNRLocatorID,PaxName)%>%
  do(data.frame(true_origin=first(.$ServiceStartCity)))

sample_data<-merge(sample_data,true_origins,
                   by.x=c("PNRLocatorID","PaxName"),
                   by.y = c("PNRLocatorID","PaxName"))
```

Next, we determine where the trip ended. If the trip is a round trip, the service end city (Final Destination) will be the same as the service start city (True Origin)
```{r}
final_destination<-sample_data%>%
  arrange(PNRLocatorID,CouponSeqNbr)%>%
  group_by(PNRLocatorID,PaxName)%>% 
  do(data.frame(final_destination=last(.$ServiceEndCity)))

sample_data<-merge(sample_data,final_destination,
                   by.x=c("PNRLocatorID","PaxName"),
                   by.y = c("PNRLocatorID","PaxName"))
```

Next, we determine what was the trips true destination. We assume this was the place where most time was spent on the trip.
```{r}
#Convert Service Start date to Date type
sample_data$ServiceStartDate<-as.Date(sample_data$ServiceStartDate)

#The place of maximum stay during the trip.
diff1<-sample_data%>%
  arrange(PNRLocatorID,CouponSeqNbr)%>%
  group_by(PNRLocatorID,PaxName)%>%
  mutate(stay=lead(ServiceStartDate)-ServiceStartDate,default=0)%>%
  select(PNRLocatorID,PaxName,ServiceStartCity,ServiceEndCity,ServiceStartDate,stay)

diff1$stay[is.na(diff1$stay)]<-0
diff1$stay<-as.numeric(diff1$stay)

true_destination<-diff1%>%
  group_by(PNRLocatorID,PaxName)%>%
  do(data.frame(true_destination= first(as.character(.$ServiceEndCity)[.$stay==max(.$stay)])))

sample_data<-merge(sample_data,true_destination,
                   by.x=c("PNRLocatorID","PaxName"),
                   by.y = c("PNRLocatorID","PaxName"))
```

Next, we determine if the trip was a one-way or round-trip. The trip is considered a round trip if the service end city (Final Destination) will be the same as the service start city (True Origin).
```{r}
sample_data%<>%
  mutate(round_trip = ifelse(as.character(true_origin)==as.character(final_destination), 1, 0))
```

Next, we determine the group size, the number of people who traveled together in each trip.
```{r}
sample_data%<>%
  group_by(PNRLocatorID)%>%
  mutate(group_size= length(unique(uid)))
```

Next, we have a special inidcator if the group-size was 1,i.e., flown by a single customer
```{r}
sample_data%<>%
  group_by(PNRLocatorID)%>%
  mutate(group= ifelse(group_size>1,1,0))
```

Next, handle seasonality in terms of quaters. Assign Q1 to Q4 based on the quarter of the year
in which the trip was made
```{r}
sample_data$ServiceStartDate<-as.Date(sample_data$ServiceStartDate)
#Convert ServiceStartDate from factor to Date format
sample_data%<>%
  group_by(PNRLocatorID,PaxName)%>%
  mutate(seasonality= ifelse(month(ServiceStartDate)>=1 & month(ServiceStartDate)<=3,"Q1",
                             ifelse(month(ServiceStartDate)>=4 & month(ServiceStartDate)<=6,"Q2",
                                    ifelse(month(ServiceStartDate)>=7 & month(ServiceStartDate)<=9,"Q3",
                                           ifelse(month(ServiceStartDate)>=10 & month(ServiceStartDate)<=12,"Q4",0)
                                           )
                                    )
                             )
         )
```

Finally, we calculate the number of days the ticket was booked in advance. It is the difference between PNRCreateDate and ServiceStartDate
```{r}
sample_data$PNRCreateDate <- as.Date(sample_data$PNRCreateDate) 
sample_data$ServiceStartDate <- as.Date(sample_data$ServiceStartDate)
sample_data%<>% 
  mutate(days_pre_booked=as.numeric(floor( difftime(ServiceStartDate,
                                                    PNRCreateDate,units=c("days")))))
```

## Customer Segmentation
We want to use the data to segment customers of Sun Country Airlines into general categories of people with similar 
flying patterns. The goal is to group the observations in the data into clusters such that every datum in a cluster is
more similar to other datums in the same cluster than it is to datums in other clusters.

### Change data granularity
In order to run the segmentation algorithm, we need to first have the data at the right granularity. Since we are
looking to segment customers, it is important to bring the data to the granularity of customers. We transform the data
such that each row represents a unique customer-PNR combination.
```{r}
sample_data%<>%
  select(PNRLocatorID, uid, PaxName, ServiceStartDate, BookingChannel, TotalDocAmt,
         UFlyRewardsNumber,UflyMemberStatus, age_group,true_origin,true_destination,
         round_trip,group_size,group, seasonality,days_pre_booked)

#This may take a considerable amount of time
customer_data<-sample_data%>%
  group_by(PNRLocatorID,uid)%>%
  summarise(PaxName=unique(PaxName), 
            ServiceStartDate=first(ServiceStartDate),
            BookingChannel=first(BookingChannel), 
            avg_amt=max(TotalDocAmt),
            UFlyRewards=first(UFlyRewardsNumber),
            UflyMemberStatus=first(UflyMemberStatus),
            age_group=last(age_group),
            true_origin=first(true_origin),
            true_destination=first(true_destination),
            round_trip=first(round_trip),
            group_size=first(group_size),
            group=first(group), 
            seasonality=last(seasonality), 
            days_pre_booked=max(days_pre_booked))

#Retaining only those attributes that are meaningful for clustering
customer_data%<>%
  select(-PNRLocatorID,-uid,-PaxName,-ServiceStartDate,-UFlyRewards)
  nrow(sample_data)

  #Granularity of data was reduced to customer level
  nrow(customer_data)
```

### Units and Scaling
The initial understanding of the data has shown us that this contains attributes of different units. Units affect what
clustering algorithms will discover. One way to try to make the clustering more coordinate- free is to transform all 
the columns to have a value between 0 and 1. This is called Normalization. There are multiple techniques of achieving 
normalization. We will be using the min-max normalization technique.
```{r}
#Min-Max normalization: x= x-max/max-min
normalize <- function(x){return ((x - min(x))/(max(x) - min(x)))}

temp<- ungroup(customer_data)

customer_data_km = mutate(temp,
                     avg_amt = normalize(avg_amt),
                     days_pre_booked = normalize(days_pre_booked),
                     group_size=normalize(group_size))
```

### Clustering algorithm
**Various clustering algorithms can be used to achieve the goal of segmentation.**

**Hierarchical clustering doesn't need to set the number of clusters in advance but is compuational expensive for large data sets.Considering the client may further apply the model to larger datasets in the future, I will not use it as the final clustering model but will use it to explore the optimal number of clusters.**

**K-means is the most popular partitional clustering method however is not feasible for non-numerical data or mixed data which is the nature of the data for this project. K-prototype is a extension of k-means for mixed data types which also inherites computational efficiency from k-means. Although nominal data can be converted into binary data in order to use k-means, this method will dramatically increase dimensions of the data.**

**Another partitional method Gaussian Mixture Model can assign each data point a membership probability for different clusters however can only process numerical data.**

**Thus, I will use k-prototype as the clustering model.**


> converting categorical variables to factors

```{r}
#convert all categorical varaibles to factors 
customer_data_km$BookingChannel <- as.factor(customer_data_km$BookingChannel)
customer_data_km$UflyMemberStatus <- as.factor(customer_data_km$UflyMemberStatus)
customer_data_km$age_group <- as.factor(customer_data_km$age_group)
customer_data_km$true_origin <- as.factor(customer_data_km$true_origin)
customer_data_km$true_destination <- as.factor(customer_data_km$true_destination)
customer_data_km$round_trip <-as.factor(customer_data_km$round_trip)
customer_data_km$group <- as.factor(customer_data_km$group)
customer_data_km$seasonality <-as.factor(customer_data_km$seasonality)
#convert customer_data_km to data frame
customer_data_km <- data.frame(customer_data_km)
```


> Selecting optimal number of clusters

####Using Hierarchical clustering to explore optimal number of clusters
```{r}
#hierarchical clustering
##install.packages("cluster")
library(cluster)
dist <- daisy(customer_data_km[,2:12], metric = "gower")
library(stats)
hcluster <- hclust(dist, method = "ward.D")
plot(hcluster, hang = 0, label = F, main = "Cluster Dendrogram")
```

**The dendrogram generated by hierarchical clustering suggests 4 or 5 are ideal number of clusters.**
<br>
<br>

####Ploting elbow curve and silhouette curve for k-prototype 

```{r, warning=FALSE}
SSE_curve <- c()
sil_curve <- c()
for (n in 2:10) {
  kcluster <- kproto(customer_data_km[,2:12], n, lambda = 0.5)
  sse <- sum(kcluster$withinss)
  SSE_curve[n-1] <- sse
  sil <- silhouette(kcluster$cluster, dist(customer_data_km[,2:12]))
  sil_curve[n-1] <- mean(sil[,3])
}

plot(2:10, SSE_curve, type="b", xlab="Number of Clusters", ylab="SSE")
plot(2:10, sil_curve, type="b", xlab="Number of Clusters", ylab="silhouette")
```
<br>
*The elbow curve and silhouette curve show that 5 is the optimal number of clusters which is consistent with the result of the dendrogram.*

> Performing clustering 

```{r}
#Perform 5 clusters k-prototype, remove PNRLocatorID from the data
kcluster5 <- kproto(customer_data_km[,2:12], 5,lambda = 0.5)
#get sizes of each cluster
kcluster5$size
```
<br>
<br>
<br>

### Visualizing the Clusters
Now that the data is divided into clusters, we can interpret the clusters by summarizing the data within each cluster. The most intuitive way of interpreting clusters is using visualizations. **I grouped all variables into 3 groups - customer profile related, booking related.**

> Differences of customer profileS among segments

I first plotted the differences between clusters for customer profile related variables including age_group and UflyMemberStatus as below. 

#### age group
**The first graph which plots the proportion of each age group in each cluster shows that cluster4 contains the largest proportion of customers above 55 years old cross clusters, while cluster1 contains the largest proportion of younger customers below 34 years old. Cluster2 and Cluster5 have similar distribution over age groups while Cluster3 has a more even mixture of all age groups.**  

#### Ufly membership
**From second graph which plots the proprotion of each type of Ufly membership in each cluster, we can find the Ufly membership stutas itself cannot clearly associated one customer with one probable customer segement and corresponding behaviors.** 

####age group and Ufly membership
**The third graph conbines the two variable agains each cluster to show their interactive relationship in different clusters. And count instead of proportion is used here. From this graph, we can further find that Cluster4 has the most number of Ufly members most of whom are above 55 years old. Cluster2 contains the second largest number of Ufly members most of whom are 35-54 years old.**

```{r}
library(ggplot2)
library(gridExtra)
#combine clustering result into the original data
cluster <- as.factor(kcluster5$cluster)
customer_data_cluster <- cbind(customer_data_km,cluster)

#customer profile
ggplot(customer_data_cluster,aes(x=cluster,fill=age_group))+geom_bar(position = 'fill')
ggplot(customer_data_cluster,aes(x=cluster,fill=UflyMemberStatus))+geom_bar(position = 'fill')
ggplot(customer_data_cluster,aes(x=UflyMemberStatus,fill=age_group))+geom_bar(position = 'stack') + facet_grid(.~cluster)
```

> Differences of booking behaviors among customer segments

I then visualized the differences between clusters in terms of booking related variables including BookingChannel, days_pre_booked, and avg_amt in below 3 grahps.Now the differences between Cluster2 and Cluster5 are uncovered and we can also find the uniqueness of Cluster3.

**Differences between Cluster2 and Cluster5:**
  + ** Most customers in Cluster2 use SCA website to book flights, while most customers in Cluster3 use Outside Booking. Also customers in Cluster2 tend to book flights in dates closer to their travel while customers in Cluster5 tend to leave more days between booking and travel.**

** Uniqueness of Cluster3:**
  + **Customers in Cluster3 tend to have unique booking behaviors. Most customers in Cluster3 use Reservation Booking while no other cluster has the similar pattern. And they tend to book fights far ahead of travel which is also unique cross clusters.**


** More insights among the other Clusters:**

  + **Interestingly, the eldest age group whom are majorly groupped into Cluster4 use SCA website most for booking which can probabliy indicate that the eldest age group is more loyal to Sun Country.**

  + **Cluster1 which mainly contains younger customers (below 34 years old) has the lowest average of days_pre_booked probabliy because younger customers are less planned and prone to spontaneous travel.**

#### Avg_amt:

Similarly to Ufly membership status, the Avg_amt is not a differentiator among clusters.
```{r}
ggplot(customer_data_cluster,aes(x=cluster,fill=BookingChannel))+geom_bar(position = 'fill')
ggplot(customer_data_cluster,aes(x=cluster,y=days_pre_booked))+geom_boxplot()
ggplot(customer_data_cluster,aes(x=cluster,y=avg_amt))+geom_boxplot()
```


Differences of trip patterns among customers segments

Below graphs plotted trip related attributes for each cluster from which we can find more differences.

#### seasonality

**Not all segments of customers tend to choose winter for travel to escape the cold weather in Minnesota.**

**Customers in Cluster 4 which contains the most eldest age group choose Q4 for their travel most frequently. Customers in Cluster 3 is the other group most of whom travel during Q4.**

**While younger customers in Cluster1 prefer to travel during Q3. And customers in Cluster2 and Cluster5 most of whom are 35-54 years old tend to travel in Q2 and Q1 respectively.**

#### round trip
**Unfortunately, round trip only constitutes less than 5% in all Clusters and it is not a differentiator for sgementation.**

```{r}
ggplot(customer_data_cluster,aes(x=cluster,fill=seasonality))+geom_bar(position = 'fill')
ggplot(customer_data_cluster,aes(x=cluster,fill=round_trip))+geom_bar(position = 'fill')
```


#### Origin and destination

**Since there are more than 50 different origins or destinations, in order to generate an clear visualization, only the most frequent origins and destinations will be labeled separately in the visualization. All the others are grouped as "Others".**
<br>
<br>
**Investigate the most frequent origins and destinations**
```{r}
#top origins
top_origin <- group_by(customer_data_cluster, true_origin)%>%
  summarise(count= n(), pct = round(n()/nrow(customer_data_cluster),2))%>%
  arrange(desc(count))%>%
  head(10)
top_origin
 
#top destinations 
top_dest <- group_by(customer_data_cluster, true_destination)%>%
  summarise(count= n(), pct = round(n()/nrow(customer_data_cluster),2))%>%
  arrange(desc(count))%>%
  head(10)
top_dest

#count of origins and destinations by cluster to check origins or destinations special to a cluster
head(table(customer_data_cluster$true_origin, customer_data_cluster$cluster))
head(table(customer_data_cluster$true_destination, customer_data_cluster$cluster))
```
<br>
<br>
**Since the true origin is dominated by MSP, only MSP is labeled separately in true_origin. The top 3 destinations MSP, LAS, MCO are labeled separately in true_destination.**
```{r}
#replace true_origin other than 'MSP' with 'Others'
customer_data_bin <-
  customer_data_cluster %>%
  filter(true_origin !='MSP')%>%
  mutate(true_origin = 'Others')%>%
  bind_rows(customer_data_cluster%>%
              filter(true_origin == 'MSP'))

#further replace true_destination other than 'MSP', 'LAS','MCO' with 'Others'
customer_data_bin <-
  customer_data_bin %>%
  filter(!true_destination %in% c('MSP', 'LAS','MCO'))%>%
  mutate(true_destination = 'Others')%>%
  bind_rows(customer_data_bin%>%
              filter(true_destination %in% c('MSP', 'LAS','MCO')))
```
<br>
**The visualization of the differences among clusters in terms of origins and destinations below shows that Cluster5 has very distinctive pattern of origins and destination. It has especially high proportion of customers starting trip from MSP and high proportion of customers heading for LAS. Other clusters have less distinguished distinctions in terms of origins and destinations.**

```{r}
ggplot(customer_data_bin,aes(x=cluster,fill=true_origin))+geom_bar(position = 'fill')
ggplot(customer_data_bin,aes(x=cluster,fill=true_destination))+geom_bar(position = 'fill')
```
<br>
<br>

#### group and group size

**Cluster3 has distinctive pattern in terms of group and group size. Majority customers in Cluster3 have companies in trips and all other Clusters are dominated by single travellers.**

```{r}
ggplot(customer_data_cluster,aes(x=cluster,fill=group))+geom_bar(position = 'fill')
ggplot(customer_data_cluster,aes(x=cluster,y=group_size))+geom_boxplot()
```
<br>
<br>
#Predictive Model
We could also usign predictive models--e.g., regression (`lm` package) or decision trees (`rpart` package)--inside of each cluster to better understand and explore their differences. 

### Target variable 
As the avg_amt is directly associated with the profit of Sun Country, I will use it as the target variable for predictive models.

### Spliting by clusters
```{r}
customer_data_fit1 <-
  customer_data_bin %>%
  filter(cluster == 1)

customer_data_fit2 <-
  customer_data_bin %>%
  filter(cluster == 2)

customer_data_fit3 <-
  customer_data_bin %>%
  filter(cluster == 3)

customer_data_fit4 <-
  customer_data_bin %>%
  filter(cluster == 4)

customer_data_fit5 <-
  customer_data_bin %>%
  filter(cluster == 5)
```

###Developing linear regression model for each cluster
```{r}
frmla <-  avg_amt ~ BookingChannel + UflyMemberStatus + age_group + round_trip + group_size + group + seasonality + days_pre_booked

#Cluster1
fit1 <- lm(frmla, data=customer_data_fit1[,2:12])
summary(fit1) 


#Cluster2
fit2 <- lm(frmla, data=customer_data_fit2[,2:12])
summary(fit2)


#Cluster3
fit3 <- lm(frmla, data=customer_data_fit3[,2:12])
summary(fit3)

#Cluster4
fit4 <- lm(frmla, data=customer_data_fit4[,2:12])
summary(fit4)

#Cluster5
fit5 <- lm(frmla, data=customer_data_fit5[,2:12])
summary(fit5)
```

### Developing linear regression model for all data
```{r}
#All data
fit <- lm(frmla, data=customer_data_cluster[,2:12])
summary(fit)
```
<br>

### Differences between clusters

<dr>
**from the summary of regression models of each cluster, we can find the relationship between avg_amt and different variables are different among clusters.**
<br>
<br>

####Predictors with significant relationship with response variables 

+ **round trip and avg_amt**
round trip has a significant possitive relationship with avg_amt in Cluster1, while such relationship doesn't exist in other clusters.

+ **group and avg_amt**
group has a significant possitive relationship with avg_amt in Cluster3, while no significant relationship in other clusters.
<br>
<br>

####The change in response variables with unit change in predictors

+ **The coefficient of the same variable can be very different in different clusters which means for unit change in the variable, the change in avg_amt is very different.**
<br>
<br>

####The fitting performance of the model

+ **The regression model developed using all data has a R squre of 10%, whereas models developed for each cluster whose data points share more similarities have R squares similar or higher(33% for Cluster3).**
<br>
<br>

**In conclusion, understanding hidden structures of data through exploratory method such as clustering before developing models can generally improve the exploratory performance of the models. Without understanding the structure inside data and simply using one model for all observations may generate suspecious result.**

<br>
<br>

## Objective Revisisted
Recall that your task is to analyze the data for potential insight to inform and answer the following questions. You should have been computing results, accompanied by exposistion, in support of answers these questions throughout. However, spend the rest of this document bringing everything you learned together to explicitly address these questions. You should also ensure that you actually discuss and characterize the various segments that you discovered.

1.  How usable is the data you received from the client (Sun Country)? Given the state of the data, what steps would you take to make it usable and useful -- for the initial assigned project and for Sun Country longer term?
    
#### The usability of the original data:

+ **Missing data**: the original data contains missing values for UflyRewardsNumber,  UflyMemberStatus etc. Keeping the missing values will make the dataset not valid for some analytic algorithms, or lose information(e.g.NA UflyMemberStatus is actually non-member). 

+ **Inconsistent data**: the original data also contains many faulty data such as Age above 120 and city codes in BookingChannel. Keeping such errors will create many distractions and undermine the quality of analysis.

+ **Granularity**: the original data is transaction data with each row representing a combination of one book, one flight and one traveler. However for most analysis such as this one, obeservations based on trips instead of flights can provide better business insight.** 

+ **Features**: relating to the granularity of the original data, all features in the original data are associated with flights rather than trips thus also contains less business insight.**

+ **Scale**: numerical variables in the original dataset is in different scales which will make result of some analytic algorithms dominated by variables of larger scales and thus become invalid.**


#### Steps to make the data usable and useful
+ **Cleaning missing data**: missing data in UflyRewardsNumber and UflyMemberStatus are replaced with best estimation such as replace NA in UflyRewardsNumber with 0 and missing values in UflyMemberStatus with "non-members".

+ **Cleaning inconsistent data**: faulty data are removed with the entire row or replaced with best estimation.**

+ **Transforming granularity**: the data was transformed from flight based into trip and traveler based.**

+ **Feature generation**: features associated each trip such as origin, destination, Oneway or RoundTrip was generated. other useful features such as Days Booked in Advance and Group Size was also generated.**

+ **Data discretization**: Age was converted into categorical Age_group assuming travellers in each group are similar to each other while different with travellers in other groups. ServiceStartDate of each trip was converted into categorical Seasonality variable assuming trips starting in the same quarter are similar to each other while different with trips in other quarters.** 

+ **Normalization**: numerical variables were normalized using Min-Max method to offset the impact of scale in order to make them usable for many analytic algorithms such as k-means in this project.**


2.  Based on what you see in the data, how many different ways can you view the information to
    paint a picture of different customer segments? Which ways offer Sun Country the most insights? How could the insights be used?
    
    
#### How the insights from visualization can be used:
+ Since the objective of this project is to find customer segments and understand their respective profiles and flying patterns in order to support product development, digital marketing or other business decisions of Sun Country. Insights from visualization is can be used for:
+ **providing easy understanding business insights for business managers.**
+ **serving as an exploratory step and preparing for supervised learnings or other analytical projects.**
+ **evaluating the performance of the segmentation.**
    
<br>    

#### Potential ways to visualize different customer segments:
    
+ **Dimensionality**: since my cluster has 11 dimensions in total with 9 categorical variables and 2 continues variables and 5 clusters, the differences among clusters can to be projected in to a plane to visualize. One plane can contain more than 2 dimensions through using colors, shapes or grouping by faceting.      
    
+ **Types of graphs**: scatter plot, bar plot for categorical variables, and density plot or histogram for numerical variables can all be used.
    
+ **Units for categorical variables**: either counts or proportion of categorical variables in each group can be used as the unit for visualization.
    
<br>    

#### The ways that can provide the most insights:
    
+ **Dimensionality**: as most variables are categorical, it is not suitable to use scatter plot with colors and shapes to add more dimensions including cluster. Plotting each nominal variables against different clusters may lose some information regarding the relationship among variables but is clear and contains the most information.

+ **Types of graph**: bar plot is the best choice to visualize two categorical data talked above.

+ **Units**: using proportion instead of counts for bar plots of each categorical data against clusters can easily visualize the difference between clusters without the impact of the size of each cluster.The lost information of cluster sizes can be plotted separately.
    

3.  How would you visualize and present the insights you found for the client? What will you do in order to show Warnken and Vaughan how the insights you derived connect to their business
    objectives?
    
    My visualization and presentation of insights can be found in the visualization part. I tried to convert the data generated by clustering into business insight that may help Warnken and Vaughan get more knowledge connect to their business objective in my communication and provide some suggestions derived from insights to show how those insights can help decision making.    
    

4.  Discuss: how much power lies in simply understanding and exploring your data? Consider the
    downside of focusing too much on fancy models.
    
    **open-mindedly exploreing, and visualizing data helps analysts to reveal the secrets beneath data and gain fresh, unknown-unknown insights about the data. Using this project as an example, we are able to achieve below tasks through exploration.**
    
+ **Data preparation:** through summarization and other exploratory activities, we can detect missing data, anomalies and outliers and clean the data which is essential for any data analysis. Models without data of high quality cannot provide high-quality result.

+ **Uncover underlying structure:** by clusering and visualization of clusters of customers, we can have a better understanding of the structure of customers. It can also serve as a starting point for detailed analysis of each clusters.Without understanding the structure inside data and simply using one model for all observations may generate suspecious result.

+ **Determine optimal parameter settings**: in this project, I plotted elbow curve and silhouette curve to find the optimal number of k for clustering model. Many other models also need analysts to input parameters and the performances of the models highly rely on those parameters.

+ **Extract important variables:** some variables were found not very useful for clustering in this project through exploration. In other cases, fancy models cannot select important variables automatically.
    
    
    
    